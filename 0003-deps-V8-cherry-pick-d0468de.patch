From 7108faf1bbcd1e542cd4c34bb57e76432da754f4 Mon Sep 17 00:00:00 2001
From: Milad Farazmand <miladfar@ca.ibm.com>
Date: Wed, 30 Jan 2019 19:08:06 +0000
Subject: [PATCH 3/3] deps: V8: cherry-pick d0468de

Original commit message:

    [heap] Fix StoreBuffer setup.

    - Solves a problem for PPC in a configuration where commit page size
      is 64K. https://chromium-review.googlesource.com/c/v8/v8/+/1149515
    - Uses existing VM allocation code to get properly aligned memory.
    - Makes sure the size for SetPermissions is a multiple of system page
      size.

    Bug:chromium:756050

    Change-Id: Ib3799ab7a3bb44b0091c234234c1cc47938379c2
    Reviewed-on: https://chromium-review.googlesource.com/1161210
    Commit-Queue: Bill Budge <bbudge@chromium.org>
    Reviewed-by: Michael Lippautz <mlippautz@chromium.org>
    Reviewed-by: Michael Starzinger <mstarzinger@chromium.org>
    Cr-Commit-Position: refs/heads/master@{#54930}

Refs: https://github.com/v8/v8/commit/d0468dede05fcd57b5a96d0fbfa117a76795fa58
---
 common.gypi                      |  2 +-
 deps/v8/src/heap/store-buffer.cc | 28 +++++++++++++++++-----------
 2 files changed, 18 insertions(+), 12 deletions(-)

diff --git a/common.gypi b/common.gypi
index 0a4ed881a5b92514d3df88ffc74555931eb71b7c..1405183bf61dfbab8c8b18a6233a08a7a1ad62ec 100644
--- a/common.gypi
+++ b/common.gypi
@@ -31,11 +31,11 @@
     # Default to -O0 for debug builds.
     'v8_optimized_debug%': 0,
 
     # Reset this number to 0 on major V8 upgrades.
     # Increment by one for each non-official patch applied to deps/v8.
-    'v8_embedder_string': '-node.12',
+    'v8_embedder_string': '-node.13',
 
     # Enable disassembler for `--print-code` v8 options
     'v8_enable_disassembler': 1,
 
     # Don't bake anything extra into the snapshot.
diff --git a/deps/v8/src/heap/store-buffer.cc b/deps/v8/src/heap/store-buffer.cc
index d73e3235c158df27756eb719643f81822d2bd015..657aa9212a6153f3bd1c44e519a3c8c7064c62b4 100644
--- a/deps/v8/src/heap/store-buffer.cc
+++ b/deps/v8/src/heap/store-buffer.cc
@@ -28,46 +28,52 @@ StoreBuffer::StoreBuffer(Heap* heap)
   insertion_callback = &InsertDuringRuntime;
   deletion_callback = &DeleteDuringRuntime;
 }
 
 void StoreBuffer::SetUp() {
-  // Allocate 3x the buffer size, so that we can start the new store buffer
-  // aligned to 2x the size.  This lets us use a bit test to detect the end of
-  // the area.
+  const size_t requested_size = kStoreBufferSize * kStoreBuffers;
+  // Allocate buffer memory aligned at least to kStoreBufferSize. This lets us
+  // use a bit test to detect the ends of the buffers.
+  const size_t alignment =
+      std::max<size_t>(kStoreBufferSize, AllocatePageSize());
+  void* hint = AlignedAddress(heap_->GetRandomMmapAddr(), alignment);
   VirtualMemory reservation;
-  if (!AllocVirtualMemory(kStoreBufferSize * 3, heap_->GetRandomMmapAddr(),
-                          &reservation)) {
+  if (!AlignedAllocVirtualMemory(requested_size, alignment, hint,
+                                 &reservation)) {
     heap_->FatalProcessOutOfMemory("StoreBuffer::SetUp");
   }
+
   Address start = reservation.address();
-  start_[0] = reinterpret_cast<Address*>(::RoundUp(start, kStoreBufferSize));
+  const size_t allocated_size = reservation.size();
+
+  start_[0] = reinterpret_cast<Address*>(start);
   limit_[0] = start_[0] + (kStoreBufferSize / kPointerSize);
   start_[1] = limit_[0];
   limit_[1] = start_[1] + (kStoreBufferSize / kPointerSize);
 
-  Address* vm_limit = reinterpret_cast<Address*>(start + reservation.size());
-
+  // Sanity check the buffers.
+  Address* vm_limit = reinterpret_cast<Address*>(start + allocated_size);
   USE(vm_limit);
   for (int i = 0; i < kStoreBuffers; i++) {
     DCHECK(reinterpret_cast<Address>(start_[i]) >= reservation.address());
     DCHECK(reinterpret_cast<Address>(limit_[i]) >= reservation.address());
     DCHECK(start_[i] <= vm_limit);
     DCHECK(limit_[i] <= vm_limit);
     DCHECK_EQ(0, reinterpret_cast<Address>(limit_[i]) & kStoreBufferMask);
   }
 
-  if (!reservation.SetPermissions(reinterpret_cast<Address>(start_[0]),
-                                  kStoreBufferSize * kStoreBuffers,
+  // Set RW permissions only on the pages we use.
+  const size_t used_size = RoundUp(requested_size, CommitPageSize());
+  if (!reservation.SetPermissions(start, used_size,
                                   PageAllocator::kReadWrite)) {
     heap_->FatalProcessOutOfMemory("StoreBuffer::SetUp");
   }
   current_ = 0;
   top_ = start_[current_];
   virtual_memory_.TakeControl(&reservation);
 }
 
-
 void StoreBuffer::TearDown() {
   if (virtual_memory_.IsReserved()) virtual_memory_.Free();
   top_ = nullptr;
   for (int i = 0; i < kStoreBuffers; i++) {
     start_[i] = nullptr;
-- 
2.20.1

